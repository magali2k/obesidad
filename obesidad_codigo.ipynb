{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb68935-ccb1-4491-a61d-e6f2803d6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las liberías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "#import pydotplus\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df5370f",
   "metadata": {},
   "source": [
    "## PREPARACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34526b-79e5-4094-a5c2-3650979f8818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cargamos el csv\n",
    "df=pd.read_csv(\"obesidad_ds.csv\",sep=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ee606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar los nombres de las columnas\n",
    "nuevos_nombres_col = ['genero', 'edad', 'altura', 'peso', 'hist_fam', 'alta_cal_frec', 'verduras', 'num_comidas', 'entrehoras', 'fumar', 'agua_dia', 'monit_cal', 'act_fis', 'uso_tecn', 'alcohol', 'transporte', 'diagnostico']\n",
    "df.columns = nuevos_nombres_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691bb81a-2d21-4881-9876-a43795e0121a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Ver los valores de cada columna\n",
    "for i in df.columns:\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6eccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar valores a numéricos\n",
    "nom_genero={'Female': 0, 'Male': 1}\n",
    "df['genero'] = df['genero'].replace(nom_genero)\n",
    "\n",
    "nom_hist_fam={'no': 0, 'yes': 1}\n",
    "df['hist_fam'] = df['hist_fam'].replace(nom_hist_fam)\n",
    "\n",
    "nom_alta_cal_frec={'no': 0, 'yes': 1}\n",
    "df['alta_cal_frec'] = df['alta_cal_frec'].replace(nom_alta_cal_frec)\n",
    "\n",
    "nom_entrehoras={'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
    "df['entrehoras'] = df['entrehoras'].replace(nom_entrehoras)\n",
    "\n",
    "nom_fumar={'no': 0, 'yes': 1}\n",
    "df['fumar'] = df['fumar'].replace(nom_fumar)\n",
    "\n",
    "nom_monit_cal={'no': 0, 'yes': 1}\n",
    "df['monit_cal'] = df['monit_cal'].replace(nom_monit_cal)\n",
    "\n",
    "nom_alcohol={'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
    "df['alcohol'] = df['alcohol'].replace(nom_alcohol)\n",
    "\n",
    "nom_transporte={'Public_Transportation': 1, 'Walking': 2, 'Automobile': 3, 'Motorbike': 4, 'Bike': 5}\n",
    "df['transporte'] = df['transporte'].replace(nom_transporte)\n",
    "\n",
    "nom_diagnostico = {'Normal_Weight': 'normal', 'Insufficient_Weight': 'insuficiente', 'Overweight_Level_I': 'sobrepeso1', 'Overweight_Level_II':'sobrepeso2', 'Obesity_Type_III':'obesidad3','Obesity_Type_II':'obesidad2', 'Obesity_Type_I':'obesidad1'}\n",
    "df['diagnostico'] = df['diagnostico'].replace(nom_diagnostico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f05974-48b9-43f5-af55-4882347d6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los valores que tiene cada columna y cuantas veces aparece cada uno de ellos\n",
    "for i in df.columns:\n",
    "    print(i,df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb12a4d-4f35-4d4b-b6a5-207d0275702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Información del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar tipo de valores\n",
    "#df['genero'] = df['genero'].astype(int)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312aad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "frecuencia_clase = df['diagnostico'].value_counts()\n",
    "\n",
    "# Define el orden deseado de los diagnósticos\n",
    "orden_diagnosticos = ['insuficiente', 'normal', 'sobrepeso1', 'sobrepeso2', 'obesidad1', 'obesidad2', 'obesidad3']\n",
    "\n",
    "# Ordena los valores y diagnósticos en función del orden deseado\n",
    "frecuencia_clase = frecuencia_clase.loc[orden_diagnosticos]\n",
    "\n",
    "plt.barh(frecuencia_clase.index, frecuencia_clase.values, color=\"lightgreen\")\n",
    "plt.xlabel('Frecuencia')\n",
    "plt.ylabel('Diagnóstico')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_diagnostico={'insuficiente': 1, 'normal': 2, 'sobrepeso1': 3, 'sobrepeso2': 4, 'obesidad1': 5, 'obesidad2': 6, 'obesidad3': 7}\n",
    "df['diagnostico'] = df['diagnostico'].replace(nom_diagnostico)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746229a-97f2-4022-acf5-5542d253b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el dataset como csv\n",
    "df.to_csv(\"obesidad_py.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996961e7",
   "metadata": {},
   "source": [
    "# PREPROCESAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos entrada y salida\n",
    "x=df.iloc[:,0:16]\n",
    "y=df[[\"diagnostico\"]]\n",
    "# Dividimos en datos de entrenamiento y de validación\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Tamaños\n",
    "x.shape, y.shape\n",
    "\n",
    "x_train.shape, y_train.shape\n",
    "\n",
    "x_test.shape, y_test.shape\n",
    "\n",
    "# Calculamos el máximo y mínimo\n",
    "maxs = np.max(x_train, axis=0)\n",
    "mins = np.min(x_train, axis=0)\n",
    "\n",
    "ranges = maxs - mins\n",
    "\n",
    "# Normalizamos las variables\n",
    "x_train = (x_train - mins) / ranges\n",
    "x_test = (x_test - mins) / ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced3d58",
   "metadata": {},
   "source": [
    "# MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d0d82",
   "metadata": {},
   "source": [
    "## Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8625f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo genérico\n",
    "DT = DecisionTreeClassifier()\n",
    "# entrenamos el modelo\n",
    "DT.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_DT = DT.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_DT))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    DT, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "DT_prec=score.mean()\n",
    "print(\"cross_value: \", DT_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_DT)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver opciones con otros parametros\n",
    "DT_combinaciones={}\n",
    "# parametros\n",
    "splitter_ = [\"best\", \"random\"]\n",
    "criterion_ = [\"gini\", \"entropy\"]\n",
    "max_features_ = [None,\"sqrt\", \"log2\"]\n",
    "porc_ = [0.2, 0.3]\n",
    "# combinaciones\n",
    "for c in criterion_:\n",
    "    for m in max_features_:\n",
    "        for s in splitter_:\n",
    "            for p in [1, 2]:\n",
    "                vector_parametros=[c,m,s,porc_[p-1]]\n",
    "                # dividimos las instancias\n",
    "                x_train, x_test, y_train, y_test = train_test_split(\n",
    "                    x, y, test_size=porc_[p - 1], random_state=42, shuffle=True\n",
    "                )\n",
    "                # modelo\n",
    "                DT = DecisionTreeClassifier(criterion=c, max_features=m, splitter=s)\n",
    "                # entrenamos el modelo\n",
    "                DT.fit(x_train, y_train)\n",
    "                # hacer predicciones\n",
    "                predicciones_DT = DT.predict(x_test)\n",
    "                # calculamos la exactitud del modelo\n",
    "                acc_1 = accuracy_score(y_test, predicciones_DT)\n",
    "                # cross value\n",
    "                kfold = StratifiedKFold(10)\n",
    "                score = cross_val_score(DT, x_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "                print(\n",
    "                    c,\n",
    "                    \",\",\n",
    "                    m,\n",
    "                    \"y\",\n",
    "                    s,\n",
    "                    \"(\",\n",
    "                    porc_[p - 1],\n",
    "                    \")\",\n",
    "                    \"-> accuracy_score: \",\n",
    "                    acc_1,\n",
    "                    \"//\",\n",
    "                    \"cross_value: \",\n",
    "                    score.mean()\n",
    "                )\n",
    "                # añadimos al diccionario esta combinación\n",
    "                DT_combinaciones[score.mean()]=vector_parametros\n",
    "                \n",
    "# calculamos la precisión máxima\n",
    "DT_max_prec = max(DT_combinaciones)\n",
    "# miramos con que parámetros se consigue esta precisión\n",
    "DT_mejor_vector_parametros = DT_combinaciones[DT_max_prec]\n",
    "print(\"mejores resultados con los parametros -> \",DT_mejor_vector_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mejor modelo (utilizando el vector conseguido anteriormente)\n",
    "DT_mejor = DecisionTreeClassifier(criterion=DT_mejor_vector_parametros[0], max_features=DT_mejor_vector_parametros[1], splitter=DT_mejor_vector_parametros[2])\n",
    "# dividimos las instancias \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=DT_mejor_vector_parametros[3], random_state=42, shuffle=True)\n",
    "# entrenamos el modelo\n",
    "DT_mejor.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_DT_mejor = DT_mejor.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_DT_mejor))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    DT_mejor, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "DT_mejor_prec=score.mean()\n",
    "print(\"cross_value: \", DT_mejor_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_DT_mejor)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8169f5e",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo genérico\n",
    "y_ravel= np.ravel(y)\n",
    "RF = RandomForestClassifier()\n",
    "# entrenamos el modelo\n",
    "y_train=y_train.values.ravel()\n",
    "RF.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_RF = RF.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_RF,zero_division=0))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    RF, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "RF_prec=score.mean()\n",
    "print(\"cross_value: \", RF_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_RF)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver opciones con otros parámetros\n",
    "RF_combinaciones={}\n",
    "# parametros\n",
    "criterion_ = [\"gini\", \"entropy\"]\n",
    "max_features_ = [None,\"sqrt\", \"log2\"]\n",
    "porc_ = [0.2, 0.3]\n",
    "# combinaciones\n",
    "for c in criterion_:\n",
    "    for m in max_features_:\n",
    "        for p in [1, 2]:\n",
    "            vector_parametros=[c,m,porc_[p-1]]\n",
    "            # dividimos las instancias\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=porc_[p - 1], random_state=42, shuffle=True)\n",
    "            y_train=y_train.values.ravel()\n",
    "            # modelo\n",
    "            RF = RandomForestClassifier(criterion=c, max_features=m)\n",
    "            # entrenamos el modelo\n",
    "            RF.fit(x_train, y_train)\n",
    "            # hacer predicciones\n",
    "            predicciones_RF = RF.predict(x_test)\n",
    "            # calculamos la exactitud del modelo\n",
    "            acc_1 = accuracy_score(y_test, predicciones_RF)\n",
    "            # cross value\n",
    "            kfold = StratifiedKFold(10)\n",
    "            score = cross_val_score(RF, x_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "            print(\n",
    "                c,\n",
    "                \"y\",\n",
    "                m,\n",
    "                \"(\",\n",
    "                porc_[p - 1],\n",
    "                \")\",\n",
    "                \"-> accuracy_score: \",\n",
    "                acc_1,\n",
    "                \"//\",\n",
    "                \"cross_value: \",\n",
    "                score.mean()\n",
    "            )\n",
    "            # añadimos al diccionario esta combinación\n",
    "            RF_combinaciones[score.mean()]=vector_parametros\n",
    "                \n",
    "# calculamos la precisión máxima\n",
    "RF_max_prec = max(RF_combinaciones)\n",
    "# miramos con que parámetros se consigue esta precisión\n",
    "RF_mejor_vector_parametros = RF_combinaciones[RF_max_prec]\n",
    "print(\"mejores resultados con los parametros -> \",RF_mejor_vector_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1252b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mejor modelo (utilizando el vector conseguido anteriormente)\n",
    "RF_mejor = RandomForestClassifier(criterion=RF_mejor_vector_parametros[0], max_features=RF_mejor_vector_parametros[1])\n",
    "# dividimos las instancias \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=RF_mejor_vector_parametros[2], random_state=42, shuffle=True)\n",
    "y_train=y_train.values.ravel()\n",
    "# entrenamos el modelo\n",
    "RF_mejor.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_RF_mejor = RF_mejor.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_RF_mejor))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    RF_mejor, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "RF_mejor_prec=score.mean()\n",
    "print(\"cross_value: \", RF_mejor_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_RF_mejor)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b04005",
   "metadata": {},
   "source": [
    "## Redes neuronales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim=[\"adam\",\"SGD\",\"RMSprop\",\"adagrad\",\"adamax\"]\n",
    "RN_combinaciones={}\n",
    "\n",
    "# Separa los atributos y las etiquetas de diagnóstico\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values -1\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escala los atributos para normalizarlos\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# ESTRUCTURA 1\n",
    "RNmodel = Sequential()\n",
    "\n",
    "# Agrega capas densas (totalmente conectadas) al modelo\n",
    "RNmodel.add(Dense(64, activation='relu', input_shape=(16,)))  # Capa oculta 1\n",
    "RNmodel.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "RNmodel.add(Dense(7, activation='softmax'))  # Capa de salida (7 niveles de obesidad)\n",
    "\n",
    "for i in optim:\n",
    "    # Compila el modelo\n",
    "    RNmodel.compile(optimizer=i, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrena el modelo\n",
    "    RNmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "    y_pred_prob = RNmodel.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    print(y_pred)\n",
    "    # Calcular precisión\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "    plt.show()\n",
    "    \n",
    "    RN_combinaciones[precision]=[1,i]\n",
    "    \n",
    "# ESTRUCTURA 2\n",
    "RNmodel = Sequential()\n",
    "\n",
    "# Agrega capas densas (totalmente conectadas) al modelo\n",
    "RNmodel.add(Dense(128, activation='relu', input_shape=(16,)))  # Capa oculta 1\n",
    "RNmodel.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "RNmodel.add(Dense(32, activation='relu'))  # Capa oculta 3\n",
    "RNmodel.add(Dense(7, activation='softmax'))  # Capa de salida (7 niveles de obesidad)\n",
    "\n",
    "for i in optim:\n",
    "    # Compila el modelo\n",
    "    RNmodel.compile(optimizer=i, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrena el modelo\n",
    "    RNmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "    y_pred_prob = RNmodel.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    # Calcular precisión\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "    plt.show()\n",
    "    \n",
    "    RN_combinaciones[precision] = [2, i]\n",
    "    \n",
    "# ESTRUCTURA 3\n",
    "RNmodel = Sequential()\n",
    "\n",
    "# Agrega capas densas (totalmente conectadas) al modelo\n",
    "RNmodel.add(Dense(64, activation='relu', input_shape=(16,)))  # Capa oculta 1\n",
    "RNmodel.add(Dense(128, activation='relu'))  # Capa oculta 2\n",
    "RNmodel.add(Dense(64, activation='relu'))  # Capa oculta 3\n",
    "RNmodel.add(Dense(32, activation='relu'))  # Capa oculta 4\n",
    "RNmodel.add(Dense(7, activation='softmax'))  # Capa de salida (7 niveles de obesidad)\n",
    "\n",
    "for i in optim:\n",
    "    # Compila el modelo\n",
    "    RNmodel.compile(optimizer=i, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrena el modelo\n",
    "    RNmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "    y_pred_prob = RNmodel.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    # Calcular precisión\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "    plt.show()\n",
    "    \n",
    "    RN_combinaciones[precision] = [3, i]\n",
    "    \n",
    "print(RN_combinaciones)\n",
    "# calculamos la precisión máxima\n",
    "RN_max_prec = max(RN_combinaciones)\n",
    "# miramos con que parámetros se consigue esta precisión\n",
    "RN_mejor_vector_parametros = RN_combinaciones[RN_max_prec]\n",
    "print(\"mejores resultados con los parametros -> \",RN_mejor_vector_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo\n",
    "\n",
    "RNmodel_mejor = Sequential()\n",
    "\n",
    "if RN_mejor_vector_parametros[0]==1:\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu', input_shape=(16,)))  # Capa oculta 1\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "    RNmodel_mejor.add(Dense(7, activation='softmax'))  # Capa de salida (7 niveles de obesidad)\n",
    "elif RN_mejor_vector_parametros[0]==2:\n",
    "    RNmodel_mejor.add(Dense(128, activation='relu', input_shape=(16,)))  # Capa oculta 1\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "    RNmodel_mejor.add(Dense(32, activation='relu'))  # Capa oculta 3\n",
    "    RNmodel_mejor.add(Dense(7, activation='softmax'))  # Capa de salida (7 niveles de obesidad)\n",
    "elif RN_mejor_vector_parametros[0]==3:\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu', input_shape=(16,)))  # Capa oculta 1\n",
    "    RNmodel_mejor.add(Dense(128, activation='relu'))  # Capa oculta 2\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu'))  # Capa oculta 3\n",
    "    RNmodel_mejor.add(Dense(32, activation='relu'))  # Capa oculta 4\n",
    "    RNmodel_mejor.add(Dense(7, activation='softmax'))  # Capa de salida (7 niveles de obesidad)\n",
    "# Compila el modelo\n",
    "RNmodel_mejor.compile(optimizer=RN_mejor_vector_parametros[1], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrena el modelo\n",
    "RNmodel_mejor.fit(x_train, y_train, epochs=40, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "y_pred_prob = RNmodel_mejor.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calcular precisión\n",
    "RN_mejor_prec = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión:\", RN_mejor_prec)\n",
    "\n",
    "# Calcular matriz de confusión\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d60cb",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score=[]\n",
    "max_score=0\n",
    "best_k=0\n",
    "for k in range(3,30):\n",
    "    knn_model=KNeighborsClassifier(n_jobs=-1,n_neighbors=k)\n",
    "    score=cross_val_score(knn_model,x_train,y_train,cv=5,scoring='accuracy')\n",
    "    if score.mean()>max_score:\n",
    "        max_score=score.mean()\n",
    "        best_k=k\n",
    "    avg_score.append(score.mean())\n",
    "\n",
    "print([best_k,max(avg_score)])\n",
    "\n",
    "max_index = avg_score.index(max(avg_score))\n",
    "max_value = max(avg_score)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(range(3, 30), avg_score, color='lightgreen', linewidth=2)  \n",
    "plt.scatter(max_index+2, max_value, color='green', marker='o', s=200)  \n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "KNN=KNeighborsClassifier(n_neighbors=best_k)\n",
    "# entrenamos el modelo\n",
    "KNN.fit(x_train,y_train)\n",
    "# hacer predicciones\n",
    "pred_KNN = KNN.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_KNN,zero_division=0))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    KNN, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "KNN_prec=score.mean()\n",
    "print(\"cross_value: \", KNN_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_KNN)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb64e0a",
   "metadata": {},
   "source": [
    "# SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "modelsvc = SVC()\n",
    "# entrenamos el modelo\n",
    "modelsvc.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_SVC = modelsvc.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_SVC,zero_division=0))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    modelsvc, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "SVC_prec=score.mean()\n",
    "print(\"cross_value: \", SVC_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_SVC)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver opciones con otros parámetros\n",
    "svc_combinaciones={}\n",
    "# parametros\n",
    "c_ = [1, 20, 100, 200]\n",
    "kernel_ = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "porc_ = [0.2, 0.3]\n",
    "# combinaciones\n",
    "for c in c_:\n",
    "    for k in kernel_:\n",
    "        for p in [1, 2]:\n",
    "            vector_parametros=[c,k,porc_[p-1]]\n",
    "            # dividimos las instancias\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=porc_[p - 1], random_state=42, shuffle=True)\n",
    "            # modelo\n",
    "            modelsvc = SVC(C=c, kernel=k)\n",
    "            # entrenamos el modelo\n",
    "            modelsvc.fit(x_train, y_train)\n",
    "            # hacer predicciones\n",
    "            predicciones_SVC = modelsvc.predict(x_test)\n",
    "            # calculamos la exactitud del modelo\n",
    "            acc_1 = accuracy_score(y_test, predicciones_SVC)\n",
    "            # cross value\n",
    "            kfold = StratifiedKFold(10)\n",
    "            score = cross_val_score(modelsvc, x_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "            print(\n",
    "                c,\n",
    "                \"y\",\n",
    "                k,\n",
    "                \"(\",\n",
    "                porc_[p - 1],\n",
    "                \")\",\n",
    "                \"-> accuracy_score: \",\n",
    "                acc_1,\n",
    "                \"//\",\n",
    "                \"cross_value: \",\n",
    "                score.mean()\n",
    "            )\n",
    "            # añadimos al diccionario esta combinación\n",
    "            svc_combinaciones[score.mean()]=vector_parametros\n",
    "                \n",
    "# calculamos la precisión máxima\n",
    "svc_max_prec = max(svc_combinaciones)\n",
    "# miramos con que parámetros se consigue esta precisión\n",
    "svc_mejor_vector_parametros = svc_combinaciones[svc_max_prec]\n",
    "print(\"mejores resultados con los parametros -> \",svc_mejor_vector_parametros) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63195d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mejor modelo (utilizando el vector conseguido anteriormente)\n",
    "svc_mejor = SVC(C=svc_mejor_vector_parametros[0], kernel=svc_mejor_vector_parametros[1])\n",
    "# dividimos las instancias \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=svc_mejor_vector_parametros[2], random_state=42, shuffle=True)\n",
    "# entrenamos el modelo\n",
    "svc_mejor.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_svc_mejor = svc_mejor.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_svc_mejor,zero_division=1))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    svc_mejor, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "svc_mejor_prec=score.mean()\n",
    "print(\"cross_value: \", svc_mejor_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_svc_mejor)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42576ad2",
   "metadata": {},
   "source": [
    "# DIAGNOSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96506c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_v=str(input(\"Ahora introduciras los datos médicos del paciente con nombre o identificador: \"))\n",
    "\n",
    "genero_v=int(input(\"genero (0=mujer)(1=hombre): \"))\n",
    "edad_v=float(input(\"edad en años: \"))\n",
    "altura_v=float(input(\"altura en metros: \"))\n",
    "peso_v=float(input(\"peso en kg: \"))\n",
    "hist_fam_v=int(input(\"¿Tiene antecedentes familiares? (0=no)(1=si): \"))\n",
    "alta_cal_frec_v=int(input(\"¿Consume comida altamente calórica? (0=no)(1=si): \"))\n",
    "verduras_v=float(input(\"Cantidad de verduras semanales: \"))\n",
    "num_comidas_v=float(input(\"Cantidad de comidas diarias: \"))\n",
    "entrehoras_v=int(input(\"¿Come entre horas? (0=nunca)(1=a veces)(2=frecuentemente)(3=siempre): \"))\n",
    "fumar_v=int(input(\"¿Fuma? (0=no)(1=si): \"))\n",
    "agua_dia_v=float(input(\"Litros de agua diarios: \"))\n",
    "monit_cal_v=int(input(\"¿Monitoriza las calorías que consume? (0=no)(1=si): \"))\n",
    "act_fis_v=float(input(\"Días semanales de actividad física: \"))\n",
    "uso_tecn_v=float(input(\"Horas diarias de uso de la tecnología: \"))\n",
    "alcohol_v=int(input(\"¿Toma bebidas alcohólicas? (0=nunca)(1=a veces)(2=frecuentemente)(3=siempre): \"))\n",
    "transporte_v=int(input(\"¿Transporte habitual?(1=transporte público)(2=a pie)(3=automóvil)(4=motocicleta)(5=bicicleta): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f3a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac=[genero_v, edad_v, altura_v, peso_v, hist_fam_v, alta_cal_frec_v, verduras_v, num_comidas_v, entrehoras_v, fumar_v, agua_dia_v, monit_cal_v, act_fis_v, uso_tecn_v, alcohol_v, transporte_v]\n",
    "#nombre_v=\"oijan\"\n",
    "#pac=[0,26,1.622,110.79,1,1,3,3,1,0,2.7,0,0,0.29,1,1]\n",
    "\n",
    "# Crear los DataFrames que necesitaremos\n",
    "df_diagnostico = pd.DataFrame(columns=['Método', 'Características', 'Precisión', 'Diagnóstico', 'Diagnóstico_nombre'])\n",
    "\n",
    "df_datos=pd.DataFrame({'medida':['género', 'edad', 'altura', 'peso', 'hist_fam', 'alta_cal_frec', 'verduras','num_comidas','entrehoras','fumar','agua_dia','monit_cal','act_fis','uso_tecn','alcohol','transporte'],\n",
    "                     'valor':pac})\n",
    "\n",
    "df_nombre=pd.DataFrame({'nombre':[nombre_v]})\n",
    "\n",
    "# Predecir diagnóstico con diferentes métodos\n",
    "DT_predict=int(DT_mejor.predict([pac]))\n",
    "RF_predict=int(RF_mejor.predict([pac]))\n",
    "pac_scaled = scaler.transform([pac])  # Escala el vector pac\n",
    "y_pred_prob = RNmodel_mejor.predict(pac_scaled)\n",
    "RN_predict = np.argmax(y_pred_prob, axis=1)\n",
    "KNN_predict=int(KNN.predict([pac]))\n",
    "svc_predict=int(svc_mejor.predict([pac]))\n",
    "\n",
    "# Añadir registros al DataFrame\n",
    "def diag_nom(diagnostico):\n",
    "    if diagnostico==0:\n",
    "        return \"insuficiente\"\n",
    "    elif diagnostico==1:\n",
    "        return \"normal\"\n",
    "    elif diagnostico==2:\n",
    "        return \"sobrepeso 1\"\n",
    "    elif diagnostico==3:\n",
    "        return \"sobrepeso 2\"\n",
    "    elif diagnostico==4:\n",
    "        return \"obesidad 1\"\n",
    "    elif diagnostico==5:\n",
    "        return \"obesidad 2\"\n",
    "    elif diagnostico==6:\n",
    "        return \"obesidad 3\"\n",
    "    \n",
    "df_diagnostico = df_diagnostico.append({'Método': 'Árbol de decisión', 'Características': DT_mejor_vector_parametros, 'Precisión': DT_mejor_prec, 'Diagnóstico': DT_predict, 'Diagnóstico_nombre': diag_nom(DT_predict)}, ignore_index=True)\n",
    "df_diagnostico = df_diagnostico.append({'Método': 'Random Forest', 'Características': RF_mejor_vector_parametros, 'Precisión': RF_mejor_prec, 'Diagnóstico': RF_predict, 'Diagnóstico_nombre': diag_nom(RF_predict)}, ignore_index=True)\n",
    "df_diagnostico = df_diagnostico.append({'Método': 'Redes neuronales', 'Características': RN_mejor_vector_parametros, 'Precisión': RN_mejor_prec, 'Diagnóstico': RN_predict[0]+1, 'Diagnóstico_nombre': diag_nom(RN_predict)}, ignore_index=True)\n",
    "df_diagnostico = df_diagnostico.append({'Método': 'KNN', 'Características': 'K='+ str(best_k), 'Precisión': KNN_prec, 'Diagnóstico': KNN_predict, 'Diagnóstico_nombre': diag_nom(KNN_predict)}, ignore_index=True)\n",
    "df_diagnostico = df_diagnostico.append({'Método': 'SVC', 'Características': svc_mejor_vector_parametros, 'Precisión': svc_mejor_prec, 'Diagnóstico': svc_predict, 'Diagnóstico_nombre': diag_nom(svc_predict)}, ignore_index=True)\n",
    "\n",
    "df_diagnostico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos los dataset como csv\n",
    "df_datos.to_csv(\"datospac_obesidad_py.csv\", index=False)\n",
    "df_diagnostico.to_csv(\"diagnostico_obesidad_py.csv\", index=False)\n",
    "df_nombre.to_csv(\"nombrepac_obesidad_py.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362fb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
